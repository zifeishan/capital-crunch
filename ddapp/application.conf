deepdive {

  db.default {
    driver   : "org.postgresql.Driver"
    url      : "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME} #"
    user     : ${PGUSER}
    password : ${PGPASSWORD}
    dbname   : ${DBNAME}
    host     : ${PGHOST}
    port     : ${PGPORT}
    gphost   : ${GPHOST}
    gpport   : ${GPPORT}
    gppath   : ${GPPATH}
  }

  # Put your variables here
  schema.variables {
    investment.is_true: Boolean
  }

  # Put your extractors here
  extraction.extractors {

    ext_investment {
      style: sql_extractor
      sql: """
        TRUNCATE investment CASCADE;
        ANALYZE investment;

        INSERT INTO investment
        SELECT investor_id, startup_id
        FROM   investor, startup;

        ANALYZE investment;

        UPDATE investment i
        SET is_true = true
        WHERE EXISTS (
          SELECT *
          FROM known_investment ki
          WHERE 
            i.investor_id = ki.investor_id AND
            i.startup_id = ki.startup_id
          );

        UPDATE investment
        SET is_true = false
        WHERE is_true is null
        AND RANDOM() < 0.01;

        UPDATE investment
        SET is_true = false
        WHERE investor_id = startup_id;

        ANALYZE investment;
      """
    }

    ext_startup_feature {
      style: tsv_extractor
      input: """
        SELECT  startup_id, path
        FROM    startup, organization_path
        WHERE   startup_id = org_id
        ;
      """
      output_relation: startup_feature
      udf: pypy udf/ext_startup_features.py
      parallelism: 8
      # udf: ${DEEPDIVE_HOME}/util/extractor_input_writer.py udf/sample_input/ext_startup_feature.tsv
      dependencies: [ext_investment]
    }

    ext_investor_feature {
      style: tsv_extractor
      input: """
        SELECT  investor_id, path
        FROM    investor, organization_path
        WHERE   investor_id = org_id
        ;
      """
      output_relation: investor_feature
      udf: pypy udf/ext_investor_features.py
      parallelism: 8
      # udf: ${DEEPDIVE_HOME}/util/extractor_input_writer.py udf/sample_input/ext_investor_feature.tsv
      dependencies: [ext_investment]
    }

    ext_pruning {
      style: "sql_extractor"
      sql: """
        DROP TABLE IF EXISTS startup_filtered;
        CREATE TABLE startup_filtered AS 
        SELECT distinct startup_id FROM startup_feature;

        DELETE FROM investment i
        WHERE NOT EXISTS (
          SELECT * FROM startup_filtered f
          WHERE i.startup_id = f.startup_id
          );

        ANALYZE investment;
      """
      dependencies: [ext_startup_feature]

    }

    ext_pruning_top_only {
      style: "sql_extractor"
      sql: """
        DROP TABLE IF EXISTS startup_investment_count;

        CREATE TABLE startup_investment_count AS 
        SELECT startup_id, count(*) from known_investment group by startup_id;

        DROP TABLE IF EXISTS investor_investment_count;

        CREATE TABLE investor_investment_count AS 
        SELECT investor_id, count(*) from known_investment group by investor_id;


        DELETE FROM investment i
        WHERE EXISTS (
          SELECT * FROM investor_investment_count f
          WHERE i.investor_id = f.investor_id
          AND f.count < 5
          );

        ANALYZE investment;

      """
      dependencies: [ext_startup_feature ext_pruning]

    }

    ext_sparse_features {
      style: "sql_extractor"
      sql: """
        DROP TABLE IF EXISTS startup_feature_cnt;

        CREATE TABLE startup_feature_cnt AS 
        SELECT feature, count(*) from startup_feature group by feature;

      """
      dependencies: [ext_startup_feature]

    }
  }


  # Put your inference rules here
  inference.factors {

    f_basic_text {
      input_query: """
        SELECT  (investor_id || '@' || feature) as feature, 
                id as "investment.id",
                is_true as "investment.is_true"
        FROM    (investment NATURAL JOIN startup_feature) t
        WHERE   type = 'basic_text'
        AND     EXISTS (
          SELECT * FROM startup_feature_cnt cnt 
          WHERE cnt.count >= 5
          AND   cnt.feature = t.feature
          )
        ;
      """  # do not ground too sparse features
      function: "IsTrue(investment.is_true)"
      weight: "?(feature)"
    }

    f_basic_numeric {
      input_query: """
        SELECT  (investor_id || '@' || feature || '==' || 
                  (CASE WHEN value >= 10 THEN 10 ELSE value END)) as feature, 
                id as "investment.id",
                is_true as "investment.is_true"
        FROM    (investment NATURAL JOIN startup_feature) t
        WHERE   type = 'basic_numeric'
        AND     EXISTS (
          SELECT * FROM startup_feature_cnt cnt 
          WHERE cnt.count >= 5
          AND   cnt.feature = t.feature
          )
        ;
      """
      function: "IsTrue(investment.is_true)"
      weight: "?(feature)"
    }

  }

  pipeline.pipelines.main: [
      ext_investment
      ext_startup_feature
      ext_investor_feature
      ext_pruning
      ext_pruning_top_only
      ext_sparse_features
      f_basic_text
      f_basic_numeric
    ]
  pipeline.run: main

  # Specify a holdout fraction
  calibration.holdout_fraction: 0.25

  inference.parallel_grounding: true

}
