deepdive {

  db.default {
    driver   : "org.postgresql.Driver"
    url      : "jdbc:postgresql://"${PGHOST}":"${PGPORT}"/"${DBNAME} #"
    user     : ${PGUSER}
    password : ${PGPASSWORD}
    dbname   : ${DBNAME}
    host     : ${PGHOST}
    port     : ${PGPORT}
    gphost   : ${GPHOST}
    gpport   : ${GPPORT}
    gppath   : ${GPPATH}
  }

  # Put your variables here
  schema.variables {
    investment.is_true: Boolean
  }

  # Put your extractors here
  extraction.extractors {

    # STARTUPS: no acquisition, no investment
    # FN: > 6 months: 

    # This cleans up the original startup table since it is wrong.
    # We extract all orgs with primary role "companies" as startups.
    ext_startup {
      style: tsv_extractor
      input: """
        SELECT  org_id, path
        FROM    organization_path
        ;
      """
      output_relation: startup
      before: udf/truncate_table.sh startup
      udf: pypy udf/ext_startup.py
      parallelism: 8
      # udf: ${DEEPDIVE_HOME}/util/extractor_input_writer.py udf/sample_input/ext_startup_feature.tsv
      dependencies: []
    }

    # 68906 startups with no investor
    # TODO do not predict unknown pairs??
    ext_investment {
      style: sql_extractor
      sql: """
        TRUNCATE investment CASCADE;
        ANALYZE investment;

        INSERT INTO investment
        SELECT i.investor_id, s.startup_id, false
        FROM startup s, investor i
        WHERE not exists (
          select * from known_investment k where k.startup_id = s.startup_id
          )
        ORDER BY RANDOM()
        LIMIT 100000;

        INSERT INTO investment
        SELECT investor_id, startup_id, true
        FROM known_investment ki
        ;

        ANALYZE investment;
      """
      dependencies: ["ext_startup"]
      # Subsampling is not very good. All the unknown are actually false.
      # after: udf/integrate-negative-examples.sh

        # INSERT INTO investment
        # SELECT investor_id, startup_id
        # FROM   investor, startup;

        # ANALYZE investment;

        # UPDATE investment i
        # SET is_true = true
        # WHERE EXISTS (
        #   SELECT *
        #   FROM known_investment ki
        #   WHERE 
        #     i.investor_id = ki.investor_id AND
        #     i.startup_id = ki.startup_id
        #   );

        # ANALYZE investment;

        # UPDATE investment
        # SET is_true = false
        # WHERE is_true is null
        # AND RANDOM() < 0.01
        # ;


    }

    ext_prepare_description {
      style: tsv_extractor
      # input: """
      #   SELECT  startup_id, path
      #   FROM    startup, organization_path
      #   WHERE   startup_id = org_id
      #   UNION
      #   SELECT  investor_id, path
      #   FROM    investor, organization_path
      #   WHERE   investor_id = org_id
      #   ;
      # """
      input: """
        SELECT  org_id, path
        FROM    organization_path
        ;
      """
      output_relation: description
      before: udf/truncate_table.sh description
      udf: pypy udf/ext_description.py
      parallelism: 8
      # udf: ${DEEPDIVE_HOME}/util/extractor_input_writer.py udf/sample_input/ext_startup_feature.tsv
      dependencies: []
    }

    # nlp_extractor only supports the default extractor.
    ext_nlp {
      input: """
        SELECT org_id, description
        FROM description 
        ORDER BY org_id ASC
        """
      output_relation: sentences
      before: udf/truncate_table.sh sentences
      udf: "udf/nlp_extractor/run.sh -k org_id -v description -l 120 -t 4"
      input_batch_size: 10
      output_batch_size: 10
      parallelism: 4
      dependencies: ["ext_prepare_description"]
    }


    ext_startup_feature {
      style: tsv_extractor
      input: """
        SELECT  startup_id, path
        FROM    startup, organization_path
        WHERE   startup_id = org_id
        ;
      """
      output_relation: startup_feature
      before: udf/truncate_table.sh startup_feature
      udf: pypy udf/ext_startup_features.py
      parallelism: 8
      # udf: ${DEEPDIVE_HOME}/util/extractor_input_writer.py udf/sample_input/ext_startup_feature.tsv
      dependencies: ["ext_investment"]
    }

    ext_startup_feature_nlp {
      style: tsv_extractor
      input: """
        SELECT  document_id,
                sentence_id,
                array_to_string(words, '~^~'),
                array_to_string(lemma, '~^~'),
                array_to_string(pos_tags, '~^~'),
                array_to_string(ner_tags, '~^~'),
                array_to_string(dep_paths, '~^~'),
                array_to_string(dep_parents, '~^~')
        FROM    startup, sentences
        WHERE   startup_id = document_id
        ;
      """
      output_relation: startup_feature
      udf: pypy udf/ext_nlp_feature.py
      parallelism: 8
      # udf: ${DEEPDIVE_HOME}/util/extractor_input_writer.py udf/sample_input/ext_startup_feature_nlp.tsv
      dependencies: ["ext_investment", "ext_startup_feature"]
    }

    ext_startup_people_feature {
      style: tsv_extractor
      input: """
        SELECT  startup_id, path
        FROM    startup, organization_path
        WHERE   startup_id = org_id
        ;
      """
      output_relation: startup_feature
      udf: pypy udf/ext_people_features.py
      parallelism: 8
      # udf: ${DEEPDIVE_HOME}/util/extractor_input_writer.py udf/sample_input/ext_startup_feature.tsv
      dependencies: ["ext_investment", "ext_startup_feature"]
    }

    ext_investor_feature {
      style: tsv_extractor
      input: """
        SELECT  investor_id, path
        FROM    investor, organization_path
        WHERE   investor_id = org_id
        ;
      """
      output_relation: investor_feature
      before: udf/truncate_table.sh investor_feature
      udf: pypy udf/ext_investor_features.py
      parallelism: 8
      # udf: ${DEEPDIVE_HOME}/util/extractor_input_writer.py udf/sample_input/ext_investor_feature.tsv
      dependencies: ["ext_investment"]
    }

    ext_investor_people_feature {
      style: tsv_extractor
      input: """
        SELECT  investor_id, path
        FROM    investor, organization_path
        WHERE   investor_id = org_id
        ;
      """
      output_relation: investor_feature
      udf: pypy udf/ext_people_features.py
      parallelism: 8
      # udf: ${DEEPDIVE_HOME}/util/extractor_input_writer.py udf/sample_input/ext_investor_feature.tsv
      dependencies: ["ext_investment", "ext_investor_feature"]
    }

    # Delete startups that has no features
    ext_pruning {
      style: "sql_extractor"
      sql: """
        DROP TABLE IF EXISTS startup_filtered;
        CREATE TABLE startup_filtered AS 
        SELECT distinct startup_id FROM startup_feature;

        DELETE FROM investment i
        WHERE NOT EXISTS (
          SELECT * FROM startup_filtered f
          WHERE i.startup_id = f.startup_id
          );

        ANALYZE investment;
      """
      dependencies: ["ext_startup_feature", "ext_startup_people_feature", "ext_startup_feature_nlp"]

    }

    # DEPRECATED
    # ext_pruning_top_only {
    #   style: "sql_extractor"
    #   sql: """
    #     DROP TABLE IF EXISTS startup_investment_count;

    #     CREATE TABLE startup_investment_count AS 
    #     SELECT startup_id, count(*) from known_investment group by startup_id;

    #     DROP TABLE IF EXISTS investor_investment_count;

    #     CREATE TABLE investor_investment_count AS 
    #     SELECT investor_id, count(*) from known_investment group by investor_id;


    #     DELETE FROM investment i
    #     WHERE EXISTS (
    #       SELECT * FROM investor_investment_count f
    #       WHERE i.investor_id = f.investor_id
    #       AND f.count < 5
    #       );

    #     ANALYZE investment;

    #   """
    #   dependencies: ["ext_startup_feature", "ext_pruning"]

    # }

    ext_prep_sparse_features {
      style: "sql_extractor"
      sql: """
        DROP TABLE IF EXISTS startup_feature_cnt;

        CREATE TABLE startup_feature_cnt AS 
        SELECT feature, count(*) from startup_feature group by feature;

        DROP TABLE IF EXISTS investor_feature_cnt;

        CREATE TABLE investor_feature_cnt AS 
        SELECT feature, count(*) from startup_feature group by feature;


        DROP TABLE IF EXISTS filtered_startup_feature CASCADE;

        CREATE TABLE filtered_startup_feature AS 
        SELECT    * 
        FROM      startup_feature f
        WHERE     EXISTS (
          SELECT * FROM startup_feature_cnt cnt 
          WHERE cnt.count >= 5
          AND   cnt.feature = f.feature
          );

        DROP TABLE IF EXISTS filtered_investor_feature CASCADE;

        CREATE TABLE filtered_investor_feature AS 
        SELECT    * 
        FROM      investor_feature f
        WHERE     EXISTS (
          SELECT * FROM investor_feature_cnt cnt 
          WHERE cnt.count >= 5
          AND   cnt.feature = f.feature
          );

        CREATE INDEX filtered_startup_feature_feature_idx 
        ON filtered_startup_feature(feature);
        
        CREATE INDEX filtered_startup_feature_value_idx ON filtered_startup_feature(value);
        
        CREATE INDEX filtered_investor_feature_feature_idx 
        ON filtered_investor_feature(feature);
        
        CREATE INDEX filtered_investor_feature_value_idx ON filtered_investor_feature(value);

      ANALYZE filtered_startup_feature;
      ANALYZE filtered_investor_feature;

      """
      dependencies: ["ext_startup_feature", "ext_startup_feature_nlp", "ext_startup_people_feature"]

    }
  }

  ext_prep_crf {
    style: "sql_extractor"
    dependencies: [ext_prep_sparse_features]
    sql: """
      DROP TABLE IF EXISTS similarity_crf;

      CREATE TABLE similarity_crf AS
        SELECT  DISTINCT
                e1.id as "investment.e1.id",
                e1.is_true as "investment.e1.is_true",
                e2.id as "investment.e2.id",
                e2.is_true as "investment.e2.is_true",
                (if1.feature || '==' || if1.value || '~~' || sf1.feature || '==' || sf1.value) AS feature
        FROM    investment e1,
                investment e2,
                filtered_startup_feature sf1,
                filtered_startup_feature sf2,
                filtered_investor_feature if1,
                filtered_investor_feature if2
        WHERE   sf1.type = 'basic_text'
        AND     sf2.type = 'basic_text'
        AND     if1.type = 'basic_text'
        AND     if2.type = 'basic_text'
        AND     e1.startup_id = sf1.startup_id
        AND     e2.startup_id = sf2.startup_id
        AND     e1.investor_id = if1.investor_id
        AND     e2.investor_id = if2.investor_id
        AND     sf1.feature = sf2.feature
        AND     sf1.value = sf2.value
        AND     if1.feature = if2.feature
        AND     if1.value = if2.value
        ;

      DROP TABLE IF EXISTS similarity_crf_distinct;

      CREATE TABLE similarity_crf_distinct AS
        SELECT DISTINCT * FROM similarity_crf;

      DROP TABLE IF EXISTS similarity_feature_cnt;

      CREATE TABLE similarity_feature_cnt AS 
      SELECT feature, count(*) from similarity_crf_distinct group by feature;

      DROP TABLE IF EXISTS filtered_similarity_crf;

      CREATE TABLE filtered_similarity_crf AS 
      SELECT    * 
      FROM      similarity_crf_distinct f
      WHERE     EXISTS (
        SELECT * FROM similarity_feature_cnt cnt 
        WHERE cnt.count >= 20 and cnt.count <= 100000
        AND   cnt.feature = f.feature
        )
      AND f.feature not like '%founded_on_year%';



    """
  }

  ext_test_training {
    style: "sql_extractor"
    dependencies: [ext_prep_sparse_features]
    sql: """
      ALTER TABLE investment DROP COLUMN IF EXISTS type;

      ALTER TABLE investment ADD COLUMN type;

      INSERT INTO investment(investor_id, startup_id, is_true, type)
      SELECT investor_id, startup_id, is_true, 'dup_training'
      FROM investment
      WHERE is_true IS NOT NULL;

    """
  }

  # Put your inference rules here
  inference.factors {

    f_basic_text {
      # TODO feature count
      input_query: """
        SELECT  (investor_id || '@' || feature) as feature, 
                id as "investment.id",
                is_true as "investment.is_true"
        FROM    (investment NATURAL JOIN startup_feature) t
        WHERE   type = 'basic_text'
        AND     EXISTS (
          SELECT * FROM startup_feature_cnt cnt 
          WHERE cnt.count >= 5
          AND   cnt.feature = t.feature
          )
        ;
      """  # do not ground too sparse features
      function: "IsTrue(investment.is_true)"
      weight: "?(feature)"
    }

    f_nlp {
      # TODO feature count
      input_query: """
        SELECT  (investor_id || '@' || feature) as feature, 
                id as "investment.id",
                is_true as "investment.is_true"
        FROM    (investment NATURAL JOIN startup_feature) t
        WHERE   type = 'nlp'
        AND     EXISTS (
          SELECT * FROM startup_feature_cnt cnt 
          WHERE cnt.count >= 5
          AND   cnt.feature = t.feature
          )
        ;
      """  # do not ground too sparse features
      function: "IsTrue(investment.is_true)"
      weight: "?(feature)"
    }

    f_basic_numeric {
      input_query: """
        SELECT  (investor_id || '@' || feature || '==' || 
                  (CASE WHEN value >= 10 THEN 10 ELSE value END)) as feature, 
                id as "investment.id",
                is_true as "investment.is_true"
        FROM    (investment NATURAL JOIN startup_feature) t
        WHERE   type = 'basic_numeric'
        AND     EXISTS (
          SELECT * FROM startup_feature_cnt cnt 
          WHERE cnt.count >= 5
          AND   cnt.feature = t.feature
          )
        ;
      """
      function: "IsTrue(investment.is_true)"
      weight: "?(feature)"
    }

    f_cheat_true {
      input_query: """
        SELECT  (investor_id || '@' || feature || '==' || 
                  (CASE WHEN value >= 10 THEN 10 ELSE value END)) as feature, 
                id as "investment.id",
                is_true as "investment.is_true"
        FROM    (investment NATURAL JOIN startup_feature) t
        WHERE   type = 'cheat'
        AND     value = 1
        ;
      """
      function: "IsTrue(investment.is_true)"
      # weight: "?(feature)"
      # weight: 5
      weight: "?"
    }

    f_cheat_false {
      input_query: """
        SELECT  (investor_id || '@' || feature || '==' || 
                  (CASE WHEN value >= 10 THEN 10 ELSE value END)) as feature, 
                id as "investment.id",
                is_true as "investment.is_true"
        FROM    (investment NATURAL JOIN startup_feature) t
        WHERE   type = 'cheat'
        AND     value = 0
        ;
      """
      function: "IsTrue(investment.is_true)"
      # weight: "?(feature)"
      # weight: -5
      weight: "?"
    }

    f_people_text {
      # TODO feature count
      input_query: """
        SELECT  (investor_id || '@' || feature) as feature, 
                id as "investment.id",
                is_true as "investment.is_true"
        FROM    (investment NATURAL JOIN startup_feature) t
        WHERE   type = 'people_text'
        AND     EXISTS (
          SELECT * FROM startup_feature_cnt cnt 
          WHERE cnt.count >= 5
          AND   cnt.feature = t.feature
          )
        ;
      """  # do not ground too sparse features
      function: "IsTrue(investment.is_true)"
      weight: "?(feature)"
    }

    f_people_numeric {
      input_query: """
        SELECT  (investor_id || '@' || feature || '==' || 
                  (CASE WHEN value >= 10 THEN 10 ELSE value END)) as feature, 
                id as "investment.id",
                is_true as "investment.is_true"
        FROM    (investment NATURAL JOIN startup_feature) t
        WHERE   type = 'people_numeric'
        AND     EXISTS (
          SELECT * FROM startup_feature_cnt cnt 
          WHERE cnt.count >= 5
          AND   cnt.feature = t.feature
          )
        ;
      """
      function: "IsTrue(investment.is_true)"
      weight: "?(feature)"
    }


    f_similarity_crf {
      input_query: """
        SELECT * FROM filtered_similarity_crf;
      """
      function: "Equal(investment.e1.is_true, investment.e2.is_true)"
      weight: "?(feature)"
    }
  }

  # DONE add people feature
  # TODO add NLP startup features
  # TODO add CRF rule

  pipeline.pipelines.nlp: [
    ext_prepare_description
    # ext_nlp
  ]

  pipeline.pipelines.main: [
    # ext_startup
    # ext_investment
    # ext_startup_feature
    # ext_startup_feature_nlp
    # ext_investor_feature
    # ext_startup_people_feature
    # ext_investor_people_feature
    # ext_pruning
    ##### ext_pruning_top_only
    # ext_prep_sparse_features
    # ext_prep_crf
    ###### Test trainingset #######
    ext_test_training
    ### Factors to use: ###
    f_basic_text
    f_basic_numeric
    # f_people_text
    # f_people_numeric
    f_nlp
    # f_cheat_true
    # f_cheat_false
    # f_similarity_crf
  ]

  # pipeline.run: nlp
  pipeline.run: main

  # Specify a holdout fraction
  # calibration.holdout_fraction: 0.25

  ######## TEST SET ##############
  # calibration.holdout_query: """
  #   INSERT INTO dd_graph_variables_holdout(variable_id) 
  #   SELECT id FROM investment 
  #   WHERE startup_id IN 
  #   ( SELECT startup_id from startup where RANDOM() < 0.25 )
  # """

  ######## TRAINING SET ##############
  calibration.holdout_query: """
    INSERT INTO dd_graph_variables_holdout(variable_id) 
    SELECT id FROM investment 
    WHERE type = 'dup_training'
  """


  inference.parallel_grounding: true

  # pipeline.relearn_from: out/2014-12-11T210113/
  # sampler.sampler_args: "-l 5000 -d 0.99 -s 1 -i 1000 --alpha 0.01"

}
